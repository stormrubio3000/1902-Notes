Alter table Movie.Movie 
	alter column GenreID int not null                changes to not null from allowing null

alter table Movie.Movie add
	FullName as (Title + ' (' + convert(nvarchar, year(ReleaseDate)) + ')')   adds in a composite column

computed columns have different options like persisted

views - 
create view Movie.NewReleases as (
	select * from Movie.Movie
	where ReleaseDate > '2019-01-01';
)                                               can be treated pretty much just like a table. Adds a bit of abstraction.


cannot add to views would have to drop view and then create again but the right way.

jk alter view actually replaces a view.

variables
Declare @action as int
set @action = 1

@ means the thing is a variable



table-valued variables
declare My_Table as table (
	col1 int, col2, int
)
insert into @My_Table                             is more temp but can be used another table.


user defined functions
	create function Movie.MoviesReleasedInYear(@year int)
	return int
	as 
	begin 
		declare @result int
		select @result = count(*)
		from Movie.Movie
		where year(ReleaseDate) = @year

		return @result
	end

select Movie.MovieReleasedInYear(2002)                     function is created and can be used again for the entire db.

functions only allow read no writing data.


triggers - 

create trigger Movie.MovieDateModified on Movie.Movie
after update
as 
begin                                          inside trigger have access to inserted and deleted
	update Movie.Movie
	set DateModified = getdate()
	where MovieId in (select MovieId from Inserted)
end 

can do triggers on insert update or delete.   can be before, after, or instead of


procedures - 

they are like functions
but allow sql commands inside them including db write
don't return anything
call them with execute, nuver inside a select or anything else.

create procedure Movie.RenameMovies (@newname nvarchar(50))
as
begin
	begin try

	if (exists(select * from Movie.Movie))
	begin	
		set @rowschanged = (select count(*) from Movie.Movie)

		update Movie.Movie
		set title = @newname
	end
	else
	begin
		raiserror('no movies found!',16,1)
	end
	end try

	begin catch
	print error_message()
	end catch
end



declare @rowschanged int

execute Movie.RenameMovies 'Movie', @rowschanged

select @rowschanged








transaction 
ACID
A- atomic - all operations succeed 100% or do nothing at all
C - Consistent - Operations should not be allowed to violate constraints.
I - Isolated - even if multiple transactions run concurrently it should be as if each was running alone.
D - Durable - transaction incomplete until written to persistent storage

kinda ignore the isolated. I mean try for it but performance takes priority.

4 levels of isolated

read_uncommitted  - best performance and least isolated, allows you to dirty read- see other transactions unfinished work.

read_committed - default. nonrepeatable read-  read row twice, to see if if something change between its change. front and back

repeatable_read - phantom read - other transactions can insert rows that meet conditions on filtering

serializable -  acts almost not in parallel. almost acts like its fully serialized aka data in a row. 

further down you go the more locks used and the worse the performance.


for multiple things that we need to do and be atomic we use transaction

begin transaction
bla
if bla
	rollback transaction 

bla
commit transaction

can put the rollback probs in catch block so no changes are made with the mistake










ADO.Net
origianlly Active Data Objects
is the brand name for all .Net data access stuff
ADO.Net is the old fashined way classically

add nugetpackage    system.data.sqlclient

sqlconnection is what we need.

it needs a string you can look at places like connectionstring.com

never put username and password in as hardcode to github. 

can either make a class with the password. and then make sure that .gitignore ignores the secret class     Secret.cs



once you have the connection set up properly you need to open it.
should open the connection with using and make sure open is in there.
sqlcommand allows you to send a sql command in its syntax to the connection

sqlreader is the return got with command.executereader()

when getting the things call them objects thing = reader["thing"];


index for reader starts at 1

sql injection is a thing gross

dataset can store data that datareader gets.

with the help of dataadaptor


using the disconnected method this time. Step 1 is still opening connection


can put 2 using on top of each other and they nest without having to indent out more.

step 2 is running the command and the adaptor into the dataset.

step 3 is closing the connection.

step 4 is processing the data through the dataset

the disconnected will never be used again for us. should know the steps and the objects and 
general process though.









ORM aka the good stuff
aka Object-relational mapper
has a few things like that. java-Hibernate. .NET Entity Framework

Entity Framework (ET) on version 6 in .Net framework
in .NET Core: EF Core 2.2
	lazy loading?!?!?!?!?!W?
	many to many without a class for the junction table


database-first approach

code-first approach

can create db with command      create database name   straight from sql server bla bla bla

will still need the secret config thing with the entityframworks


EF database first approach

1. have startup project on one hand and a data access library project.
2. need a reference data access from start up.( add reference from class to program project
3.add nuget package.
	EFC.tools
	EFC.sqlserver    to the main

	and EFC.sqlserver           to the library

look at helloentityframework dependencies.    Which project dependiances really matter and you should do it on the startup


4. view -> other windows -> package manager console

make sure server connection string is right. should have proper username and password and initial catalog
must be able to compile to run properly
5. run command--- Scaffold-DbContext "<your connection string>" Microsoft.EntityFrameworkCore.SqlServer -Project projectname -Force


all as one line



6. delete on configuring override thing its dumb and we don't like it

That should make all the required classes in your library that fit into the db

7.  anytime we change the database go to step 4.

The class created is meant to be slightly readable and that kind of making is called fluent API
because they want to you to be able to sorta understand whats going on


scaffolding will config the modles in onmodelcreating.  which is the right way to do things

2 other ways one is dataannotations 
other is convention based coding. lets just ignore those other 2 exist though and only use the default one.

context is how you get into things    should just make a new var this is a 

var optionbuilder = new dbcontextoptionbuilder<moviescontext>();
optionbuilder.useqlserver(connectionstring);
var options = optionsbuilder.options;


using ( var dbcontext = new moviescontext(options))
{
	lots of setup but after from the rest its easy stuff
	can do like a foreach look with (var movie in dbcontext.Movie) where movie is the movie generated class at that point
}


maybe just use nuget packages with the solution   sql server should be on both tools on the main



insert,update,delete in EF

AddMovie(dbcontext)


static void AddMovie(moviecontext dbcontext)
{
	genre actiongenere = dbcontext.genre.First(x => x.Name.Contains("Action"));
	movie newMovie = new movie
	{
		Title = "srgsergserg",
		ReleaseDate = new DateTime(2003,1,1),
		Genre = actiongenre;
	}

	dbcontext.Movie.Add(newMovie);

	dbcontext.SaveChanges();
}

objects that we get out of dbsets are tracked. so things like dbcontext.savechanges() can just know everything that changes.

dbcontext are cheap so can make a lot and save changes and get rid of them often


Adding in an interface to this

stick with IEnumerable for interfaces so youll need a get for each data type

going to have to use context.update  with the thing he linked https://docs.microsoft.com/en-us/ef/core/saving/basic
Going to have to basically make the framework then do the scafoldding then re do all of the functions.
Partially to use the interface the way that he wants but also to use the add,delete,and update functions that we get in and from the context
The context is basically the database and we are making function calls through the different pre generated classes.
These classes will need to be used over ours for all of the saving,deleteing, and updating so we might asa well phase
out everything that isn't just base temp data after we have our database set up and some sample data put in there to load.


interface basically works as a abstract class kind? just tells you what functions need to exist and kinda what they should take and give
Then a class will inherit? that interface and give methods to those functions that the interface made.



instead of either copying everything from the new classes from database to local and using them or using the old logic
on all of the new classes do a combination. Where we would just replace the datatypes in our old with the contextual data 
that we are getting straight from the database.








